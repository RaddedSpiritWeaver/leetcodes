{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a rows x cols matrix grid representing a field of cherries where grid[i][j] represents the number of cherries that you can collect from the (i, j) cell.\n",
    "\n",
    "You have two robots that can collect cherries for you:\n",
    "\n",
    "Robot #1 is located at the top-left corner (0, 0), and\n",
    "Robot #2 is located at the top-right corner (0, cols - 1).\n",
    "Return the maximum number of cherries collection using both robots by following the rules below:\n",
    "\n",
    "From a cell (i, j), robots can move to cell (i + 1, j - 1), (i + 1, j), or (i + 1, j + 1).\n",
    "When any robot passes through a cell, It picks up all cherries, and the cell becomes an empty cell.\n",
    "When both robots stay in the same cell, only one takes the cherries.\n",
    "Both robots cannot move outside of the grid at any moment.\n",
    "Both robots should reach the bottom row in grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   TODO: should remove the shape thing and use a class maybe to store the value\n",
    "def get_valid_actions(field_shape: tuple, current_loc:tuple, parent:bool) -> list[tuple]:\n",
    "    \"\"\"\n",
    "    shapes are in (i, j) format\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if not parent:\n",
    "        next_i = current_loc[0] + 1\n",
    "    else:\n",
    "        next_i = current_loc[0] - 1\n",
    "    \n",
    "    #   check i\n",
    "    if next_i >= field_shape[0] or next_i < 0:\n",
    "        return result\n",
    "    \n",
    "    for step in range(-1, 2):\n",
    "        next_j = current_loc[1] + step\n",
    "        #   check j\n",
    "        if next_j < 0 or next_j >= field_shape[1]:\n",
    "            continue\n",
    "        result.append((next_i, next_j))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   test\n",
    "list_shape = (5,5)\n",
    "locs = [(0,0), (0,4), (1,3)]\n",
    "for x in locs:\n",
    "    print(get_valid_actions(list_shape,x, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   should start at a given loc\n",
    "#   expand my next moves\n",
    "#   store the path that im taking\n",
    "list_shape = (5,5)\n",
    "paths = []\n",
    "\n",
    "def bfs(current_loc:tuple, path:list):\n",
    "    path.append(current_loc)\n",
    "    #   get next possible actions:\n",
    "    next_actions = get_valid_actions(list_shape, current_loc)\n",
    "    if not next_actions:\n",
    "        #   termination\n",
    "        paths.append(path)\n",
    "        return\n",
    "    \n",
    "    for action in next_actions:\n",
    "        #   important to use a new object and not the main reference\n",
    "        bfs(action, copy.copy(path))\n",
    "\n",
    "bfs((0,0),[])\n",
    "for x in paths:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]\n",
    "\n",
    "if not a:\n",
    "    print(\"!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   DP Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   single agent\n",
    "def build_max_paths(board: list[list[int]]):\n",
    "    paths = {}\n",
    "    board_shape = (len(board), len(board[0]))\n",
    "    max_rewards = [[0] * board_shape[1] for _ in range(board_shape[0])]\n",
    "    frontier = []\n",
    "    frontier.append((0,0))\n",
    "    #   since we are using a queue we are going bfs which, since we need the parents data for the next layer\n",
    "    #   while there is a node in the frontier\n",
    "    while frontier:\n",
    "        node = frontier.pop(0)\n",
    "        \n",
    "        #   get the parents\n",
    "        parent_nodes = get_valid_actions(board_shape, node, parent=True)\n",
    "        \n",
    "        if parent_nodes:\n",
    "            #   select the max parent and make the path\n",
    "            max_parent_val = -1\n",
    "            max_parent = None\n",
    "            for parent in parent_nodes:\n",
    "                if max_rewards[parent[0]][parent[1]] > max_parent_val:\n",
    "                    max_parent = parent\n",
    "                    max_parent_val = max_rewards[parent[0]][parent[1]]\n",
    "        \n",
    "            #   for i_j key format\n",
    "            key = f\"{max_parent[0]}_{max_parent[1]}\"\n",
    "            parent_path = paths[key]\n",
    "            node_path = copy.copy(parent_path)\n",
    "            node_path.append(node)\n",
    "                \n",
    "            node_max_reward = max_parent_val + board[node[0]][node[1]]\n",
    "            max_rewards[node[0]][node[1]] = node_max_reward\n",
    "            print(f\"max reward added for {node}: {node_max_reward}\")\n",
    "        else:\n",
    "            #   basically for the first level\n",
    "            max_rewards[node[0]][node[1]] = board[node[0]][node[1]]\n",
    "            print(f\"max reward added for {node}: {board[node[0]][node[1]]}\")\n",
    "            node_path = [node]\n",
    "        \n",
    "        #   update paths and max values for the node coordinates\n",
    "        \n",
    "        node_key = f\"{node[0]}_{node[1]}\"\n",
    "        paths[node_key] = node_path\n",
    "        print(f\"adding node path for key:{node_key} : {node_path}\")\n",
    "        #   get the children and add them to frontier\n",
    "        children = get_valid_actions(board_shape, node, parent=False)\n",
    "        frontier = frontier + children\n",
    "        \n",
    "    return paths, max_rewards\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = [[3,1,1],[2,5,1],[1,5,5],[2,1,1]]\n",
    "\n",
    "paths, max_rewards = build_max_paths(board)\n",
    "\n",
    "print(paths)\n",
    "print(max_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP Double Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   //  use a hash map with children as keys and add their parents\n",
    "def get_next_nodes(pos_a:tuple, pos_b:tuple, board_shape:tuple):\n",
    "    a_next = get_valid_actions(board_shape, pos_a, parent=False)\n",
    "    b_next = get_valid_actions(board_shape, pos_b, parent=False)\n",
    "    res = []\n",
    "    for a in a_next:\n",
    "        for b in b_next:\n",
    "            res.append((a, b))\n",
    "    return res\n",
    "\n",
    "get_next_nodes((0,0), (0,1), (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_up(board: list[list[int]]):\n",
    "    board_shape = (len(board), len(board[0]))\n",
    "    #   use key format: i::aj__bj\n",
    "    max_rewards = {}\n",
    "    fathers = {}\n",
    "    \n",
    "    #   do the first level\n",
    "    positions = ((0,0), (0, board_shape[1] - 1))\n",
    "    position_key = f\"{0}::{0}__{board_shape[1] - 1}\"\n",
    "    max_reward_level_0 = board[0][0] + board[0][board_shape[1] - 1]\n",
    "    max_rewards[position_key] = max_reward_level_0\n",
    "    #   child expansion\n",
    "    frontier = get_next_nodes(positions[0], positions[1], board_shape)\n",
    "    for child in frontier:\n",
    "        child_key = f\"{child[0][0]}::{child[0][1]}__{child[1][1]}\"\n",
    "        try:\n",
    "            fathers[child_key].append(positions)\n",
    "        except KeyError:\n",
    "            fathers[child_key] = [positions]\n",
    "    \n",
    "    while frontier:\n",
    "        positions = frontier.pop(0)\n",
    "        position_key = f\"{positions[0][0]}::{positions[0][1]}__{positions[1][1]}\"\n",
    "        \n",
    "        #   get parents\n",
    "        parents = fathers[position_key]\n",
    "        \n",
    "        #   select max parent\n",
    "        max_val = -1\n",
    "        for parent in parents:\n",
    "            parent_key = f\"{parent[0][0]}::{parent[0][1]}__{parent[1][1]}\"\n",
    "            if max_val < max_rewards[parent_key]:\n",
    "                max_val = max_rewards[parent_key]\n",
    "        \n",
    "        #   update the max value for current state\n",
    "        if positions[0][1] == positions[1][1]:\n",
    "            #   only one robot takes it\n",
    "            current_reward = max_val + board[positions[0][0]][positions[0][1]]\n",
    "        else:\n",
    "            current_reward = max_val + board[positions[0][0]][positions[0][1]] + board[positions[0][0]][positions[1][1]]\n",
    "        \n",
    "        max_rewards[position_key] = current_reward   \n",
    "\n",
    "        #   child expansion\n",
    "        children = get_next_nodes(positions[0], positions[1], board_shape)\n",
    "        for child in children:\n",
    "            child_key = f\"{child[0][0]}::{child[0][1]}__{child[1][1]}\"\n",
    "            try:\n",
    "                fathers[child_key].append(positions)\n",
    "            except KeyError:\n",
    "                fathers[child_key] = [positions]\n",
    "                \n",
    "        frontier = frontier + children\n",
    "        \n",
    "    return max_rewards\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = [[1,1],[1,1]]\n",
    "\n",
    "max_rewards = build_up(board)\n",
    "\n",
    "max = -1\n",
    "i = len(board) - 1\n",
    "max_j = len(board[0])\n",
    "for j in range(max_j):\n",
    "    for k in range(max_j):\n",
    "        key = f\"{i}::{j}__{k}\"\n",
    "        try:\n",
    "            if max < max_rewards[key]:\n",
    "                max = max_rewards[key]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "print(max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
